[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a place for me to document my journey in learning data science in a more rigorous way. While I did a lot of coding and modeling as a chemist, I did not formally learn to code or about modeling and machine learning frameworks. (I wish I had! My post-doc would have been a lot smoother.)\nMost of my academic work was in Matlab so I chose to start this process with R because it looked more similar than Python."
  },
  {
    "objectID": "blogroll.html",
    "href": "blogroll.html",
    "title": "Blog Roll",
    "section": "",
    "text": "Blogs:\nR Bloggers\nTutorials I’ve followed:\nWord Games Project:\nr letter frequency in R packages via R-Bloggers\nSetting Up Webpage:\nCreating Quarto Websites by Sam Csik\nAlbert Rapp: The ultimate guide to starting a Quarto blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Louise E. Sinks",
    "section": "",
    "text": "EMPLOYMENT\nFreelance Technical Consultant 2017- present\nVice President US Nano LLC 2011-2017\nEDUCATION\nUniversity of Pennsylvania 2005-2011\nPostdoctoral Research Fellow 2008-2011\nNIH National Research Service Award Postdoctoral Fellow 2005-2008\nUniversity of Aarhus summer 2009\nVisiting Researcher, Center for Oxygen Microscopic Imaging\nNorthwestern University Evanston, IL 1999-2004\nMS and PhD in Chemistry\nUniversity of Virginia Charlottesville, VA 1995-1999\nBS in Chemistry with Honors, Minor: Math, fulfilled requirements for a BA in Physics\nCERTIFICATIONS\nDataCamp Data Scientist Professional Certificate\nGoogle Data Analytics Certificate"
  },
  {
    "objectID": "posts/2023-03-14-tester-post/index.html",
    "href": "posts/2023-03-14-tester-post/index.html",
    "title": "Creating a Blog",
    "section": "",
    "text": "This is my first blog entry. I am following the tutorials here:\nhttps://ucsb-meds.github.io/creating-quarto-websites/#where-you-should-start-changing-stuff\nhttps://samanthacsik.github.io/posts/2022-10-24-quarto-blogs/\nGenerally, this process has been a nightmare. The website is being created within RStudio, then pushed to GitHub and published through GitHub pages. As I’ve made changes per the tutorial, I have repeatedly been unable to push changes to GitHub due to a variety of fatal errors and merge conflicts. Since I’m only working in a single place I have no idea where all these merge conflicts are arising from. I don’t understand how I can have everything in sync everywhere, make a local change, commit it, and then be unable to push it. I’ve had to delete the GitHub repository at least half a dozen times and recreate it from my local version because I couldn’t find any way to fix the conflicts and fatal errors. I’m not sure whose fault this is (Quarto, GitHub or RStudio). It could be my fault, but I really don’t understand why things are breaking so spectacularly. I’ve used git/ GitHub for version control of R projects before and I’ve never had an error. (I don’t really see how you can get a merge conflict if you are the only person working on a project and you are only working at a single location, but maybe I’m failing to envision some use case.)\nI decided to go with Quarto because it is now built-in to RStudio and the tutorials by Samantha Csik seemed very clear. (And to be fair, they are! Very easy to follow.) The tutorials I found for R Markdown to make a website seemed a little more involved and a little more kludgey.\nCouldn’t have done it without the best helper turtle in the world. Mac took a lot of executive naps to work on the problem.\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{e.sinks,\n  author = {Louise E. Sinks},\n  title = {Creating a {Blog}},\n  url = {https://lsinks.github.io/2023-03-14_tester-post},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLouise E. Sinks. n.d. “Creating a Blog.” https://lsinks.github.io/2023-03-14_tester-post."
  },
  {
    "objectID": "posts/2023-03-21-tidytuesday-programming-languages/index.html",
    "href": "posts/2023-03-21-tidytuesday-programming-languages/index.html",
    "title": "TidyTuesday Week 12: Programming Languages",
    "section": "",
    "text": "This is my first attempt at Tidy Tuesday. The dataset today is about Programming Languages. The sample visualizations are about the comment codes.\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\nlibrary(gt)\nlibrary(ggrepel)\n\nLoad the data first. There has been some cleaning done as outlined on the TidyTuesday github page.\n\n# Get the Data\n\n# Read in with tidytuesdayR package \n# This loads the readme and all the datasets for the week of interest\n\n# Either ISO-8601 date or year/week works!\n\n#tuesdata <- tidytuesdayR::tt_load('2023-03-21')\ntuesdata <- tidytuesdayR::tt_load(2023, week = 12)\n\nlanguages <- tuesdata$languages\n\nFirst, let’s look at how complete the data is. The skimr package produces nice summary information about the variables and their completeness.\n\nskim(languages)\n\n\nData summary\n\n\nName\nlanguages\n\n\nNumber of rows\n4303\n\n\nNumber of columns\n49\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n21\n\n\nlogical\n4\n\n\nnumeric\n24\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\npldb_id\n0\n1.00\n1\n52\n0\n4303\n0\n\n\ntitle\n0\n1.00\n1\n56\n0\n4267\n0\n\n\ndescription\n3480\n0.19\n4\n2273\n0\n811\n0\n\n\ntype\n0\n1.00\n2\n27\n0\n40\n0\n\n\ncreators\n3203\n0.26\n2\n253\n0\n985\n0\n\n\nwebsite\n2928\n0.32\n13\n131\n0\n1368\n0\n\n\ndomain_name\n3588\n0.17\n6\n32\n0\n700\n0\n\n\nreference\n2314\n0.46\n15\n251\n0\n1955\n0\n\n\ngithub_repo\n3402\n0.21\n25\n73\n0\n897\n0\n\n\ngithub_repo_description\n3438\n0.20\n4\n419\n0\n853\n0\n\n\ngithub_language\n3829\n0.11\n1\n30\n0\n474\n0\n\n\ngithub_language_tm_scope\n3837\n0.11\n4\n34\n0\n361\n0\n\n\ngithub_language_type\n3837\n0.11\n4\n11\n0\n4\n0\n\n\ngithub_language_ace_mode\n3838\n0.11\n1\n16\n0\n96\n0\n\n\ngithub_language_file_extensions\n3833\n0.11\n1\n606\n0\n466\n0\n\n\nwikipedia\n2731\n0.37\n32\n104\n0\n1566\n0\n\n\nwikipedia_summary\n2884\n0.33\n17\n6741\n0\n1407\n0\n\n\nwikipedia_related\n3145\n0.27\n1\n1761\n0\n1059\n0\n\n\nline_comment_token\n3831\n0.11\n1\n7\n0\n23\n0\n\n\norigin_community\n1190\n0.72\n3\n305\n0\n2232\n0\n\n\nfile_type\n3213\n0.25\n2\n6\n0\n4\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nfeatures_has_comments\n3683\n0.14\n1.00\nTRU: 617, FAL: 3\n\n\nfeatures_has_semantic_indentation\n3722\n0.14\n0.11\nFAL: 516, TRU: 65\n\n\nfeatures_has_line_comments\n3765\n0.13\n0.96\nTRU: 517, FAL: 21\n\n\nis_open_source\n3792\n0.12\n0.89\nTRU: 453, FAL: 58\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nappeared\n0\n1.00\n1991.11\n111.44\n-2000\n1984.00\n1997.0\n2012.00\n2023\n▁▁▁▁▇\n\n\ndomain_name_registered\n3801\n0.12\n2011.33\n7.02\n1990\n2007.00\n2013.0\n2017.00\n2023\n▁▃▃▇▆\n\n\nisbndb\n3217\n0.25\n7.71\n33.16\n0\n0.00\n0.0\n2.00\n400\n▇▁▁▁▁\n\n\nbook_count\n0\n1.00\n2.08\n17.34\n0\n0.00\n0.0\n0.00\n401\n▇▁▁▁▁\n\n\nsemantic_scholar\n3545\n0.18\n3.79\n8.32\n0\n0.00\n0.0\n3.00\n52\n▇▁▁▁▁\n\n\nlanguage_rank\n0\n1.00\n2151.00\n1242.31\n0\n1075.50\n2151.0\n3226.50\n4302\n▇▇▇▇▇\n\n\ngithub_repo_stars\n3414\n0.21\n2127.40\n7554.02\n0\n29.00\n194.0\n1071.00\n88526\n▇▁▁▁▁\n\n\ngithub_repo_forks\n3417\n0.21\n261.29\n1203.00\n0\n2.25\n16.0\n91.50\n23732\n▇▁▁▁▁\n\n\ngithub_repo_updated\n3418\n0.21\n2021.39\n1.76\n2012\n2022.00\n2022.0\n2022.00\n2023\n▁▁▁▁▇\n\n\ngithub_repo_subscribers\n3418\n0.21\n62.34\n200.88\n0\n4.00\n13.0\n44.00\n2910\n▇▁▁▁▁\n\n\ngithub_repo_created\n3425\n0.20\n2015.84\n3.48\n2006\n2013.00\n2016.0\n2019.00\n2022\n▁▅▇▇▇\n\n\ngithub_repo_issues\n3518\n0.18\n123.03\n546.26\n0\n1.00\n9.0\n61.00\n9522\n▇▁▁▁▁\n\n\ngithub_repo_first_commit\n3567\n0.17\n2014.74\n4.99\n1987\n2012.00\n2015.0\n2018.00\n2022\n▁▁▁▆▇\n\n\ngithub_language_repos\n3833\n0.11\n197134.67\n1226900.57\n0\n91.25\n725.5\n7900.25\n16046489\n▇▁▁▁▁\n\n\nwikipedia_daily_page_views\n2837\n0.34\n227.13\n783.55\n-1\n9.00\n24.0\n99.00\n13394\n▇▁▁▁▁\n\n\nwikipedia_backlinks_count\n2877\n0.33\n318.55\n1635.29\n1\n13.00\n39.0\n126.00\n34348\n▇▁▁▁▁\n\n\nwikipedia_page_id\n2893\n0.33\n9167847.21\n13506832.90\n928\n375153.75\n2114700.5\n12321223.00\n63063548\n▇▁▁▁▁\n\n\nwikipedia_appeared\n2958\n0.31\n1991.14\n17.03\n1830\n1980.00\n1994.0\n2005.00\n2019\n▁▁▁▃▇\n\n\nwikipedia_created\n3040\n0.29\n2005.75\n3.77\n2001\n2003.00\n2005.0\n2007.00\n2020\n▇▇▂▁▁\n\n\nwikipedia_revision_count\n3130\n0.27\n330.43\n813.26\n1\n35.00\n84.0\n242.00\n10104\n▇▁▁▁▁\n\n\nlast_activity\n0\n1.00\n2000.62\n84.60\n-900\n1992.00\n2006.0\n2021.00\n2023\n▁▁▁▁▇\n\n\nnumber_of_users\n0\n1.00\n13771.26\n227712.95\n0\n0.00\n20.0\n230.00\n7179119\n▇▁▁▁▁\n\n\nnumber_of_jobs\n0\n1.00\n422.18\n12572.99\n0\n0.00\n0.0\n0.00\n771996\n▇▁▁▁▁\n\n\ncentral_package_repository_count\n1482\n0.66\n0.00\n0.00\n0\n0.00\n0.0\n0.00\n0\n▁▁▇▁▁\n\n\n\n\n\nThe data is pretty incomplete. Only 9 of the 49 variables are fully complete. The line comment token is only 0.110 complete and the has comments is only 0.144 complete. This variable has only 3 false values; it is likely that the missing data is skewed towards false. It is more likely that you’d complete this entry if there were a comment, than if there weren’t. It is also possible that the cleaning and prep done to prepare the #TidyTuesday dataset removed some entries which did have FALSE values for the comments.\nThere are some funny entries that appeared in the skim report, like -2000 as the year the earliest language appeared. It turns out this is Babylonian numerals, so it probably correct. This does show there is a lot more than computer languages in this dataset though.\nLooking through the variables, I see there is a “type” in the data dictionary, and it appears that “pl” means programming language. So let’s filter for that. (I couldn’t find an explanation of this variable on https://pldb.com/) It is used on various pages, but I couldn’t find the definition of the types.\nAlso, rank starts at 0, and I’d like it to start at 1.\n\nprogramming_lang <- languages %>%\n  filter(type == 'pl') %>%\n  select(-starts_with(\"github\"), -starts_with(\"wikipedia\"),\n         -description, -creators, -(website:semantic_scholar)) %>%\n  mutate(language_rank = language_rank + 1)\n\nskim(programming_lang)\n\n\nData summary\n\n\nName\nprogramming_lang\n\n\nNumber of rows\n3368\n\n\nNumber of columns\n16\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlogical\n4\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\npldb_id\n0\n1.00\n1\n52\n0\n3368\n0\n\n\ntitle\n0\n1.00\n1\n54\n0\n3347\n0\n\n\ntype\n0\n1.00\n2\n2\n0\n1\n0\n\n\nline_comment_token\n3002\n0.11\n1\n3\n0\n18\n0\n\n\norigin_community\n883\n0.74\n3\n176\n0\n1825\n0\n\n\nfile_type\n2609\n0.23\n4\n4\n0\n1\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nfeatures_has_comments\n2886\n0.14\n1.00\nTRU: 482\n\n\nfeatures_has_semantic_indentation\n2917\n0.13\n0.09\nFAL: 410, TRU: 41\n\n\nfeatures_has_line_comments\n2954\n0.12\n0.97\nTRU: 401, FAL: 13\n\n\nis_open_source\n2984\n0.11\n0.85\nTRU: 328, FAL: 56\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nappeared\n0\n1.00\n1994.16\n17.34\n1948\n1982.0\n1994.0\n2010.0\n2022\n▁▅▇▇▇\n\n\nlanguage_rank\n0\n1.00\n2296.75\n1249.08\n1\n1243.5\n2334.5\n3423.5\n4303\n▆▆▆▆▇\n\n\nlast_activity\n0\n1.00\n2002.04\n17.91\n1951\n1989.0\n2005.0\n2019.0\n2023\n▁▂▃▆▇\n\n\nnumber_of_users\n0\n1.00\n10793.85\n190197.19\n0\n0.0\n15.0\n165.0\n5962666\n▇▁▁▁▁\n\n\nnumber_of_jobs\n0\n1.00\n160.22\n2692.65\n0\n0.0\n0.0\n0.0\n85206\n▇▁▁▁▁\n\n\ncentral_package_repository_count\n939\n0.72\n0.00\n0.00\n0\n0.0\n0.0\n0.0\n0\n▁▁▇▁▁\n\n\n\n\n\nThis now produces a dataset with 0.143 completeness for features_has_comments. All non-missing entries are TRUE, which again suggests that FALSE is over represented in the missing data.\nLet’s only look at the programming languages that have data for comments.\n\nprogramming_lang <- programming_lang %>%\n  filter(features_has_comments == TRUE)\n\nskim(programming_lang)\n\n\nData summary\n\n\nName\nprogramming_lang\n\n\nNumber of rows\n482\n\n\nNumber of columns\n16\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nlogical\n4\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\npldb_id\n0\n1.00\n1\n35\n0\n482\n0\n\n\ntitle\n0\n1.00\n1\n45\n0\n481\n0\n\n\ntype\n0\n1.00\n2\n2\n0\n1\n0\n\n\nline_comment_token\n120\n0.75\n1\n3\n0\n18\n0\n\n\norigin_community\n112\n0.77\n3\n105\n0\n311\n0\n\n\nfile_type\n146\n0.70\n4\n4\n0\n1\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nfeatures_has_comments\n0\n1.00\n1.00\nTRU: 482\n\n\nfeatures_has_semantic_indentation\n57\n0.88\n0.05\nFAL: 405, TRU: 20\n\n\nfeatures_has_line_comments\n71\n0.85\n0.97\nTRU: 400, FAL: 11\n\n\nis_open_source\n305\n0.37\n0.91\nTRU: 161, FAL: 16\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nappeared\n0\n1.00\n2000.17\n14.07\n1957\n1991.00\n2003.0\n2011.00\n2022\n▁▂▆▇▇\n\n\nlanguage_rank\n0\n1.00\n656.10\n559.75\n1\n201.25\n515.5\n997.25\n2994\n▇▃▂▁▁\n\n\nlast_activity\n0\n1.00\n2016.20\n8.27\n1967\n2011.00\n2022.0\n2022.00\n2023\n▁▁▁▂▇\n\n\nnumber_of_users\n0\n1.00\n62892.08\n462314.18\n0\n112.00\n437.5\n1615.25\n5962666\n▇▁▁▁▁\n\n\nnumber_of_jobs\n0\n1.00\n971.30\n6489.83\n0\n0.00\n0.0\n0.00\n85206\n▇▁▁▁▁\n\n\ncentral_package_repository_count\n136\n0.72\n0.00\n0.00\n0\n0.00\n0.0\n0.00\n0\n▁▁▇▁▁\n\n\n\n\n\nThis subset is still moderately incomplete for information about comments. Only 75% of the data has the type of comment entered (#, //, etc). 86% of the entries are completed for “feature_has_line_comments” which indicates if comments must occupy a single line or if they can be made inline.\n\nprogramming_lang %>% filter(is.na(line_comment_token) == FALSE) %>%\n  group_by(line_comment_token) %>%\n  count(line_comment_token) %>%\n  ggplot(aes(fct_rev(fct_reorder(line_comment_token, n)), n)) +\n  geom_col(fill = \"dodgerblue2\") +\n  ylab(\"Count\") +\n  xlab(\"Comment Token\") +\n  ggtitle(\"Popularity of different comment tokens\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45,  vjust = 0.25, hjust = 0.25))\n\n\n\n\nLet’s make a nice table of the popular comment types.\n\n# | label: table-tokens\nprogramming_lang2 <- programming_lang %>%\n  filter(is.na(line_comment_token) == FALSE) %>%\n  count(line_comment_token, sort = TRUE) \n\nprogramming_lang2 %>%\ngt() %>%\ntab_header(title = \"Most Common Comment Tokens\") %>%\ncols_label(line_comment_token = \"Token\", n = \"# of Languages that use token\")\n\n\n\n\n\n  \n    \n      Most Common Comment Tokens\n    \n    \n  \n  \n    \n      Token\n      # of Languages that use token\n    \n  \n  \n    //\n161\n    #\n70\n    ;\n49\n    --\n31\n    '\n16\n    %\n12\n    !\n7\n    *\n5\n    REM\n2\n    *>\n1\n    ---\n1\n    /\n1\n    NB.\n1\n    \\\n1\n    \\*\n1\n    __\n1\n    ~\n1\n    ⍝\n1\n  \n  \n  \n\n\n\n\nThere is a language rank, which measures the popularity of the language based on signals such as number of users and number of jobs. Let’s see the average rank of languages for each token.\n\nprogramming_lang %>% filter(is.na(line_comment_token) == FALSE) %>%\n  group_by(line_comment_token) %>%\n  summarize(avg_rank = mean(language_rank)) %>%\n  ggplot(aes((fct_reorder(line_comment_token, avg_rank)), avg_rank)) +\n  geom_col(fill = \"dodgerblue2\") +\n  ylab(\"Average Rank of Language\") +\n  xlab(\"Comment Token\") +\n  ggtitle(\"Average rank of languages using different comment tokens\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45,  vjust = 0.25, hjust = 0.25))\n\n\n\n\nThe highest (average) ranked token is “*>”. What languages use this?\n\nprogramming_lang %>% filter(line_comment_token == \"*>\") %>%\n  select(title, language_rank, line_comment_token)\n\n# A tibble: 1 × 3\n  title language_rank line_comment_token\n  <chr>         <dbl> <chr>             \n1 COBOL            19 *>                \n\n\nOnly COBOL does, so the rank of this token isn’t diluted by many less popular languages. We can view the distribution of the language ranks for all the tokens.\n\nprogramming_lang %>%\n  filter(is.na(line_comment_token) == FALSE) %>%\n  ggplot(aes(line_comment_token, language_rank)) +\n  geom_boxplot(color = \"dodgerblue2\") +\n  ggtitle(\"The rank of languages by token.\") +\n  xlab(\"Token\") +\n  ylab (\"Language Rank\") +\n  theme_classic()\n\n\n\n\nOkay, let’s clean this up. I’d like it sorted by the median rank. Remeber rank is in reverse numerical order- a low number means a higher rank.\n\nprogramming_lang %>%\n  filter(is.na(line_comment_token) == FALSE) %>%\n  ggplot(aes(fct_reorder(line_comment_token, language_rank,\n                         .fun = median, .desc = FALSE), language_rank)) +\n  geom_boxplot(color = \"dodgerblue2\") +\n  ggtitle(\"The rank of languages by token\") +\n  xlab(\"Token\") +\n  ylab(\"Language Rank\") +\n    theme_classic()\n\n\n\n\nLet’s see the most popular language for each symbol. There might be a way to do this all at once, but I’m going to pull it out with joins to previous tables I’ve created.\n\nprogramming_lang3 <- programming_lang %>%\n  filter(is.na(line_comment_token) == FALSE) %>%\n  group_by(line_comment_token) %>%\n  summarize(highest_rank = min(language_rank)) \n\njoin_madness <- programming_lang2 %>%\n  left_join(programming_lang3, by = \"line_comment_token\") %>% \n  left_join(programming_lang, \n            by = c(\"highest_rank\" = \"language_rank\",\n                   \"line_comment_token\" = \"line_comment_token\")) \n\njoin_madness <- join_madness %>%\n  select(line_comment_token, n, highest_rank, title, appeared, number_of_users,\n         number_of_jobs)\n\nSo now we have a bunch of summarized data in a single dataframe. Here’s a graph. It is saying something, but I’m not sure what. When you can’t come up with a concise title, then you probably don’t know what you are trying to say…\n\njoin_madness %>%\n  ggplot(aes(highest_rank, n, size = log(number_of_users), \n             color = log(number_of_users), label = line_comment_token)) +\n  scale_y_log10() +\n  scale_x_log10() +\n  geom_text_repel(show.legend = FALSE) +\n  ggtitle(\"Popularity of tokens by language rank and usage\") +\n  xlab(\"Highest Rank of language using Token\") +\n  ylab(\"Number of Languages using token\") +\n  theme_classic()\n\n\n\n\nThis is a visualization of the highest ranked languages for each token. The number of users of the dominant language is also encoded in the size and color of the label. Having it ordered makes it difficult to tell if Java or Python is the most popular/ highest ranked language.\n\njoin_madness %>%\n  ggplot(aes(fct_rev(fct_reorder(line_comment_token, highest_rank)), n,\n             size = log(number_of_users), color = log(number_of_users),\n             label = title)) +\n # geom_point() +\n  scale_y_log10() +\n  geom_text_repel(show.legend = FALSE) +\n   ggtitle(\"The Most Popular Language for Each Comment Token\") +\n  xlab(\"Token\") +\n  ylab(\"Number of languages using token\") +\n  theme_classic()\n\n\n\n\nHere is the same graph just ordered “alphabetically” by token.\n\njoin_madness %>%\n  ggplot(aes(line_comment_token, n, size = log(number_of_users), \n             color = log(number_of_users), label = title)) +\n # geom_point() +\n  scale_y_log10() +\n  geom_text_repel(show.legend = FALSE) +\n   ggtitle(\"The Most Popular Language for Each Comment Token\") +\n  xlab(\"Token\") +\n  ylab(\"Number of languages using token\") +\n  theme_classic()\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{e.sinks,\n  author = {Louise E. Sinks},\n  title = {TidyTuesday {Week} 12: {Programming} {Languages}},\n  url = {https://lsinks.github.io/posts/2023-03-21-tidytuesday-programming-languages/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLouise E. Sinks. n.d. “TidyTuesday Week 12: Programming\nLanguages.” https://lsinks.github.io/posts/2023-03-21-tidytuesday-programming-languages/."
  },
  {
    "objectID": "posts/2023-03-24-tidytuesday-figure-polishing/index.html",
    "href": "posts/2023-03-24-tidytuesday-figure-polishing/index.html",
    "title": "TidyTuesday Week 12: Programming Languages Revisited",
    "section": "",
    "text": "This week, I participated in my first #TidyTuesday challenge. My goal was to get something out on the day of the challenge rather than perfection. I did notice that the skimr output wasn’t formatted nicely on the webpage. Today, I’m going to delve into the skimr and Quarto documentation and make a nicer version of the output. Secondly, I’m going to fix up my final figure, which is the one I shared on social media:"
  },
  {
    "objectID": "posts/2023-03-24-tidytuesday-figure-polishing/index.html#skimr-to-understand-your-data",
    "href": "posts/2023-03-24-tidytuesday-figure-polishing/index.html#skimr-to-understand-your-data",
    "title": "TidyTuesday Week 12: Programming Languages Revisited",
    "section": "Skimr to understand your data",
    "text": "Skimr to understand your data\nSkimr is a package that provides statistical summaries of the variables in your dataframe. It also provides information about the missingness of each variable.\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\nlibrary(gt)\nlibrary(ggrepel)\nlibrary(visdat) # visualizing missing data in dataframe\n\n\n# Get the Data\n\n# Read in with tidytuesdayR package \n# This loads the readme and all the datasets for the week of interest\n\n# Either ISO-8601 date or year/week works!\n\n#tuesdata <- tidytuesdayR::tt_load('2023-03-21')\ntuesdata <- tidytuesdayR::tt_load(2023, week = 12)\n\nlanguages <- tuesdata$languages\n\n\nCustomizing the skim Output\nMy main objection is that the numerical summary is too wide and has a scroll bar. I especially want the histogram to be viewable on the first screen. I also don’t particularly care about all the quartile information; min and max are enough. If I want to delve more into the stats of a variable, I will do it another way, not with skimr.\nFirst, quarto lets you expand the output of the code chunk to fill the page via the option “#| column: page”, so I’ll do that. Next, I’ll create a custom skim function that drops the p25, p50, and p75 output from the summary of the numerical variables.\n\nmy_skim <- skim_with(numeric = sfl(p25 = NULL, p50 = NULL, p75 = NULL)) \n\nmy_skim(languages)\n\n\nData summary\n\n\nName\nlanguages\n\n\nNumber of rows\n4303\n\n\nNumber of columns\n49\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n21\n\n\nlogical\n4\n\n\nnumeric\n24\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\npldb_id\n0\n1.00\n1\n52\n0\n4303\n0\n\n\ntitle\n0\n1.00\n1\n56\n0\n4267\n0\n\n\ndescription\n3480\n0.19\n4\n2273\n0\n811\n0\n\n\ntype\n0\n1.00\n2\n27\n0\n40\n0\n\n\ncreators\n3203\n0.26\n2\n253\n0\n985\n0\n\n\nwebsite\n2928\n0.32\n13\n131\n0\n1368\n0\n\n\ndomain_name\n3588\n0.17\n6\n32\n0\n700\n0\n\n\nreference\n2314\n0.46\n15\n251\n0\n1955\n0\n\n\ngithub_repo\n3402\n0.21\n25\n73\n0\n897\n0\n\n\ngithub_repo_description\n3438\n0.20\n4\n419\n0\n853\n0\n\n\ngithub_language\n3829\n0.11\n1\n30\n0\n474\n0\n\n\ngithub_language_tm_scope\n3837\n0.11\n4\n34\n0\n361\n0\n\n\ngithub_language_type\n3837\n0.11\n4\n11\n0\n4\n0\n\n\ngithub_language_ace_mode\n3838\n0.11\n1\n16\n0\n96\n0\n\n\ngithub_language_file_extensions\n3833\n0.11\n1\n606\n0\n466\n0\n\n\nwikipedia\n2731\n0.37\n32\n104\n0\n1566\n0\n\n\nwikipedia_summary\n2884\n0.33\n17\n6741\n0\n1407\n0\n\n\nwikipedia_related\n3145\n0.27\n1\n1761\n0\n1059\n0\n\n\nline_comment_token\n3831\n0.11\n1\n7\n0\n23\n0\n\n\norigin_community\n1190\n0.72\n3\n305\n0\n2232\n0\n\n\nfile_type\n3213\n0.25\n2\n6\n0\n4\n0\n\n\n\nVariable type: logical\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nfeatures_has_comments\n3683\n0.14\n1.00\nTRU: 617, FAL: 3\n\n\nfeatures_has_semantic_indentation\n3722\n0.14\n0.11\nFAL: 516, TRU: 65\n\n\nfeatures_has_line_comments\n3765\n0.13\n0.96\nTRU: 517, FAL: 21\n\n\nis_open_source\n3792\n0.12\n0.89\nTRU: 453, FAL: 58\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np100\nhist\n\n\n\n\nappeared\n0\n1.00\n1991.11\n111.44\n-2000\n2023\n▁▁▁▁▇\n\n\ndomain_name_registered\n3801\n0.12\n2011.33\n7.02\n1990\n2023\n▁▃▃▇▆\n\n\nisbndb\n3217\n0.25\n7.71\n33.16\n0\n400\n▇▁▁▁▁\n\n\nbook_count\n0\n1.00\n2.08\n17.34\n0\n401\n▇▁▁▁▁\n\n\nsemantic_scholar\n3545\n0.18\n3.79\n8.32\n0\n52\n▇▁▁▁▁\n\n\nlanguage_rank\n0\n1.00\n2151.00\n1242.31\n0\n4302\n▇▇▇▇▇\n\n\ngithub_repo_stars\n3414\n0.21\n2127.40\n7554.02\n0\n88526\n▇▁▁▁▁\n\n\ngithub_repo_forks\n3417\n0.21\n261.29\n1203.00\n0\n23732\n▇▁▁▁▁\n\n\ngithub_repo_updated\n3418\n0.21\n2021.39\n1.76\n2012\n2023\n▁▁▁▁▇\n\n\ngithub_repo_subscribers\n3418\n0.21\n62.34\n200.88\n0\n2910\n▇▁▁▁▁\n\n\ngithub_repo_created\n3425\n0.20\n2015.84\n3.48\n2006\n2022\n▁▅▇▇▇\n\n\ngithub_repo_issues\n3518\n0.18\n123.03\n546.26\n0\n9522\n▇▁▁▁▁\n\n\ngithub_repo_first_commit\n3567\n0.17\n2014.74\n4.99\n1987\n2022\n▁▁▁▆▇\n\n\ngithub_language_repos\n3833\n0.11\n197134.67\n1226900.57\n0\n16046489\n▇▁▁▁▁\n\n\nwikipedia_daily_page_views\n2837\n0.34\n227.13\n783.55\n-1\n13394\n▇▁▁▁▁\n\n\nwikipedia_backlinks_count\n2877\n0.33\n318.55\n1635.29\n1\n34348\n▇▁▁▁▁\n\n\nwikipedia_page_id\n2893\n0.33\n9167847.21\n13506832.90\n928\n63063548\n▇▁▁▁▁\n\n\nwikipedia_appeared\n2958\n0.31\n1991.14\n17.03\n1830\n2019\n▁▁▁▃▇\n\n\nwikipedia_created\n3040\n0.29\n2005.75\n3.77\n2001\n2020\n▇▇▂▁▁\n\n\nwikipedia_revision_count\n3130\n0.27\n330.43\n813.26\n1\n10104\n▇▁▁▁▁\n\n\nlast_activity\n0\n1.00\n2000.62\n84.60\n-900\n2023\n▁▁▁▁▇\n\n\nnumber_of_users\n0\n1.00\n13771.26\n227712.95\n0\n7179119\n▇▁▁▁▁\n\n\nnumber_of_jobs\n0\n1.00\n422.18\n12572.99\n0\n771996\n▇▁▁▁▁\n\n\ncentral_package_repository_count\n1482\n0.66\n0.00\n0.00\n0\n0\n▁▁▇▁▁\n\n\n\n\n\nThis output is much nicer. It is a bit wall of text though. I wouldn’t recommend using this in reports, but it is a useful tool when doing your initial dataset analysis. (As a side note, I have noticed skimr doesn’t work well on Kaggle. It performs as expected if you are in interactive mode, but it fails when you try to save the notebook or run non-interactively.)\n\n\nStyling skim output with gt\nIf, for some reason, you did need to include output/ visualizations about missingness in a report, I’d probably recreate visualizations or tables by class of variable, especially if you have many variables, as I do here.\nHere’s an example for numeric variables, of which there are 24 in the dataset. First, we will skim the data and then use the gt package to style the resulting dataframe as a table. I used a built-in style, but each table element can be individually customized.\n\nlanguages_numeric <- languages %>%\n  select_if(is.numeric)\n\nlang_numeric_skim <- my_skim(languages_numeric)\n\nlang_numeric_skim %>%\n  select(-skim_type)   %>% \n  gt() %>%\n  cols_label(n_missing = \"# Missing\", complete_rate = \"Completeness\", \n             numeric.mean = \"Mean\", numeric.sd = \"Standard Deviation\",\n             numeric.p0 = \"Min\", numeric.p100 = \"Max\",\n             numeric.hist = \"Histogram\") %>%\n  opt_stylize(style = 6, color = \"blue\", add_row_striping = TRUE) %>%\n  tab_header(title = \"Summary of Numerical Variables in Languages\") \n\n\n\n\n\n  \n    \n      Summary of Numerical Variables in Languages\n    \n    \n  \n  \n    \n      skim_variable\n      # Missing\n      Completeness\n      Mean\n      Standard Deviation\n      Min\n      Max\n      Histogram\n    \n  \n  \n    appeared\n0\n1.0000000\n1.991105e+03\n1.114434e+02\n-2000\n2023\n▁▁▁▁▇\n    domain_name_registered\n3801\n0.1166628\n2.011333e+03\n7.021132e+00\n1990\n2023\n▁▃▃▇▆\n    isbndb\n3217\n0.2523821\n7.706262e+00\n3.316421e+01\n0\n400\n▇▁▁▁▁\n    book_count\n0\n1.0000000\n2.079479e+00\n1.734465e+01\n0\n401\n▇▁▁▁▁\n    semantic_scholar\n3545\n0.1761562\n3.794195e+00\n8.316231e+00\n0\n52\n▇▁▁▁▁\n    language_rank\n0\n1.0000000\n2.151000e+03\n1.242313e+03\n0\n4302\n▇▇▇▇▇\n    github_repo_stars\n3414\n0.2066000\n2.127403e+03\n7.554016e+03\n0\n88526\n▇▁▁▁▁\n    github_repo_forks\n3417\n0.2059029\n2.612867e+02\n1.203003e+03\n0\n23732\n▇▁▁▁▁\n    github_repo_updated\n3418\n0.2056705\n2.021390e+03\n1.763285e+00\n2012\n2023\n▁▁▁▁▇\n    github_repo_subscribers\n3418\n0.2056705\n6.234237e+01\n2.008820e+02\n0\n2910\n▇▁▁▁▁\n    github_repo_created\n3425\n0.2040437\n2.015843e+03\n3.479589e+00\n2006\n2022\n▁▅▇▇▇\n    github_repo_issues\n3518\n0.1824309\n1.230344e+02\n5.462553e+02\n0\n9522\n▇▁▁▁▁\n    github_repo_first_commit\n3567\n0.1710435\n2.014739e+03\n4.985409e+00\n1987\n2022\n▁▁▁▆▇\n    github_language_repos\n3833\n0.1092261\n1.971347e+05\n1.226901e+06\n0\n16046489\n▇▁▁▁▁\n    wikipedia_daily_page_views\n2837\n0.3406925\n2.271330e+02\n7.835524e+02\n-1\n13394\n▇▁▁▁▁\n    wikipedia_backlinks_count\n2877\n0.3313967\n3.185484e+02\n1.635289e+03\n1\n34348\n▇▁▁▁▁\n    wikipedia_page_id\n2893\n0.3276784\n9.167847e+06\n1.350683e+07\n928\n63063548\n▇▁▁▁▁\n    wikipedia_appeared\n2958\n0.3125726\n1.991144e+03\n1.702650e+01\n1830\n2019\n▁▁▁▃▇\n    wikipedia_created\n3040\n0.2935162\n2.005748e+03\n3.768240e+00\n2001\n2020\n▇▇▂▁▁\n    wikipedia_revision_count\n3130\n0.2726005\n3.304314e+02\n8.132556e+02\n1\n10104\n▇▁▁▁▁\n    last_activity\n0\n1.0000000\n2.000616e+03\n8.459776e+01\n-900\n2023\n▁▁▁▁▇\n    number_of_users\n0\n1.0000000\n1.377126e+04\n2.277129e+05\n0\n7179119\n▇▁▁▁▁\n    number_of_jobs\n0\n1.0000000\n4.221838e+02\n1.257299e+04\n0\n771996\n▇▁▁▁▁\n    central_package_repository_count\n1482\n0.6555891\n0.000000e+00\n0.000000e+00\n0\n0\n▁▁▇▁▁\n  \n  \n  \n\n\n\n\n\n\nVisualizing Missingness with visdat\nThe visdat package makes ggplot- compatible missingness plots. The cluster = TRUE option groups variables that share missingness. Here we see that usually if some of the GitHub data is missing, then all of the GitHub data is missing. The percent missing is listed for each variable, and the overall missingness of the dataset is shown in the legend.\nNote vis_miss doesn’t work on very large datasets. The documentation suggests keeping the number of records below 1,000. A more extensive package for exploratory visualizations called naniar could also be used.\n\nlanguages_numeric %>%\nvis_miss(cluster = TRUE) +\nggtitle(\"Missing Data in the Languages Dataset\") +\n  #theme_classic() +\n  theme(axis.text.x = element_text(size = 8, angle = 90))"
  },
  {
    "objectID": "posts/2023-03-24-tidytuesday-figure-polishing/index.html#improving-the-most-popular-language-for-each-comment-token-figure",
    "href": "posts/2023-03-24-tidytuesday-figure-polishing/index.html#improving-the-most-popular-language-for-each-comment-token-figure",
    "title": "TidyTuesday Week 12: Programming Languages Revisited",
    "section": "Improving “The Most Popular Language for Each Comment Token” Figure",
    "text": "Improving “The Most Popular Language for Each Comment Token” Figure\n\njoined <- read_csv(\"processed_lang.csv\" , show_col_types = FALSE)\n\nNow the original figure:\n\njoined %>%\n  ggplot(aes(line_comment_token, n, size = log(number_of_users), \n             color = log(number_of_users), label = title)) +\n # geom_point() +\n  scale_y_log10() +\n  geom_text_repel(show.legend = FALSE) +\n   ggtitle(\"The Most Popular Language for Each Comment Token\") +\n  xlab(\"Token\") +\n  ylab(\"Number of languages using token\") +\n  theme_classic()\n\n\n\n\nI thought I had noted this in the previous post, but one of the tokens, ⍝ , is rendered as an empty box in the ggplot figures. I thought fixing this would be easy. First, I thought I could just pass the Unicode value for that symbol. Then, when that didn’t work, I thought I could change the font to one supporting that symbol. Supposedly, changing the font should be easy, yet after 3 hours working on it, I still had blank squares. There is a nice tutorial on changing fonts in ggplot that did not work until I found someone with the same issue. The solution is to add a line of code that doesn’t make much sense to me : windowsFonts(\"Cambria Math\" = windowsFont(\"Cambria Math\"))\nI saw a nice TidyTuesday figure on Twitter:\n\n\nMy submission for #TidyTuesday, Week 12 on programming languages. I explore jobs per users.Code: https://t.co/bV9DUHZmro pic.twitter.com/2D5YLnE5yz\n\n— Mitsuo Shiota (@mitsuoxv) March 21, 2023\n\n\nwith a caption referencing the original dataset. I’d like to add that. I generally want to increase the figure’s legibility and flip the color scale so that darker blue corresponds to more users. I also don’t think what popular means is entirely clear, so I’d like to explain more fully what I’m graphing.\n\nwindowsFonts(\"Cambria Math\" = windowsFont(\"Cambria Math\"))\njoined %>%\n  ggplot(aes(line_comment_token, n, size = log(number_of_users), \n             color = log(number_of_users), label = title)) +\n  scale_y_log10() +\n  geom_text_repel(show.legend = FALSE) +\n    scale_colour_gradient(high = \"#08306b\", low = \"#6baed6\") + \n   labs(title = \"The Most Popular Language for Each Comment Token\",\n       subtitle = \"Based on # Users and Rank\",\n       caption = \"data from https://pldb.com/\") +\n  xlab(\"Token\") +\n  ylab(\"Number of languages using token\") +\n  theme_classic(base_size = 16) +\n  theme(text = element_text( family = \"Cambria Math\")) +\n  theme(axis.text.x = element_text(face = \"bold\"))"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Entries",
    "section": "",
    "text": "Creating a Blog\n\n\n\nQuarto\n\n\nR\n\n\nturtle\n\n\n\nTrying to create a Quarto Blog\n\n\n\nLouise E. Sinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 12: Programming Languages\n\n\n\nR\n\n\nTidyTuesday\n\n\nR-code\n\n\nCode-Along\n\n\n\nTidyTuesday: How to comment in Various Programming Languages\n\n\n\nLouise E. Sinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Week 12: Programming Languages Revisited\n\n\n\nR\n\n\nTidyTuesday\n\n\nR-code\n\n\nCode-Along\n\n\nData-Viz\n\n\nskimr\n\n\n\nTidyTuesday: Polishing\n\n\n\nLouise E. Sinks\n\n\n\n\n\n\n\n\nNo matching items"
  }
]