---
title: "TidyTuesday Week 12: Programming Languages Revisited"
description: "TidyTuesday: Polishing "
author:
  - name: Louise E. Sinks
    url: https://lsinks.github.io/
    date: 03-22-2023
categories: [R, TidyTuesday, R-code, Code-Along, Data-Viz, skimr] # self-defined categories
citation:
  url: https://lsinks.github.io/ 
image: pop-lang-by-token.png
draft: true # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

This week, I participated in my first #TidyTuesday challenge. My goal was to get something out on the day of the challenge rather than perfection. I did notice that the skimr output wasn't formatted nicely on the webpage. Today, I'm going to delve into the skimr and Quarto documentation and make a nicer version of the output. Secondly, I'm going to fix up my final figure, which is the one I shared on social media.

## Skimr

Skimr is a package that provides statistical summaries of the variables in your dataframe. It also provides information about the missingness of each variable.

```{r}
#| label: loading-libraries
#| warning: false
#| output: false
library(tidytuesdayR)
library(tidyverse)
library(skimr)
library(ggthemes)
library(gt)
library(ggrepel)
library(visdat) # visualizing missing data in dataframe
```

```{r}
#| label: load-data
#| warning: false
#| output: false
# Get the Data

# Read in with tidytuesdayR package 
# This loads the readme and all the datasets for the week of interest

# Either ISO-8601 date or year/week works!

#tuesdata <- tidytuesdayR::tt_load('2023-03-21')
tuesdata <- tidytuesdayR::tt_load(2023, week = 12)

languages <- tuesdata$languages
```

My main objection is that the numerical summary is too wide and has a scroll bar. I especially want the histogram to be viewable on the first screen. I also don't particularly care about all the quartile information; min and max are enough. If I want to delve more into the stats of a variable, I will do it another way, not with skimr.

First, quarto lets you expand the output of the code chunk to fill the page via the option "#\| column: page", so I'll do that. Next, I'll create a custom skim function that drops the p25, p50, and p75 output from the summary of the numerical variables.

```{r}
#| label: custom-skim-functions
#| column: page

my_skim <- skim_with(numeric = sfl(p25 = NULL, p50 = NULL, p75 = NULL)) 

my_skim(languages)
```
This output is much nicer. It is a bit wall of text though. I wouldn't recommend using this in reports, but it is a useful tool when doing your initial dataset analysis. (As a side note, I have noticed skimr doesn't work well on Kaggle. It performs as expected if you are in interactive mode, but it fails when you try to save the notebook or run non-interactively.)

If, for some reason, you did need to include output/ visualizations about missingness in a report, I'd probably recreate visualizations or tables by class of variable, especially if you have many variables, as I do here.

Here's an example for numeric variables, of which there are 24 in the dataset. First, we will skim the data and then use the gt package to style the resulting dataframe as a table.  I used a built-in style, but each table element can be individually customized.

```{r}
#| column: page
languages_numeric <- languages %>%
  select_if(is.numeric)

lang_numeric_skim <- my_skim(languages_numeric)

lang_numeric_skim %>%
  select(-skim_type)   %>% 
  gt() %>%
  cols_label(n_missing = "# Missing", complete_rate = "Completeness", 
             numeric.mean = "Mean", numeric.sd = "Standard Deviation",
             numeric.p0 = "Min", numeric.p100 = "Max",
             numeric.hist = "Histogram") %>%
  opt_stylize(style = 6, color = "blue", add_row_striping = TRUE) %>%
  tab_header(title = "Summary of Numerical Variables in Languages") 

```

The visdat package makes ggplot- compatible missingness plots. The cluster = TRUE option groups variables that share missingness. Here we see that usually if some of the GitHub data is missing, then all of the GitHub data is missing. The percent missing is listed for each variable, and the overall missingness of the dataset is shown in the legend.

Note vis_miss doesn't work on very large datasets. The documentation suggests keeping the number of records below 1,000. A more extensive package for exploratory visualizations called naniar could also be used.

```{r}
languages_numeric %>%
vis_miss(cluster = TRUE) +
ggtitle("Missing Data in the Languages Dataset") +
  #theme_classic() +
  theme(axis.text.x = element_text(size = 8, angle = 90))
```

## Improving the Popular language for each comment token figure

```{r}
joined <- read_csv("processed_lang.csv" , show_col_types = FALSE)
```

Now the original figure:

```{r}
#| label: lang-token-graph-undordered
joined %>%
  ggplot(aes(line_comment_token, n, size = log(number_of_users), 
             color = log(number_of_users), label = title)) +
 # geom_point() +
  scale_y_log10() +
  geom_text_repel(show.legend = FALSE) +
   ggtitle("The Most Popular Language for Each Comment Token") +
  xlab("Token") +
  ylab("Number of languages using token") +
  theme_classic()
```
I thought I had noted this in the previous post, but one of the tokens, , is rendered as an empty box in the ggplot figures. I thought fixing this would be easy. First, I thought I could just pass the Unicode value for that symbol. Then, when that didn't work, I thought I could change the font to one supporting that symbol. Supposedly, changing the font should be easy, yet after 3 hours working on it, I still had blank squares. So I will come back to that in another post.

I saw a nice TidyTuesday figure on Twitter with a caption referencing the original dataset. I'd like to add that. I generally want to increase the figure's legibility and flip the color scale so that darker blue corresponds to more users. I also don't think what popular means is entirely clear, so I'd like to explain more fully what I'm graphing.
 
  #https://stackoverflow.com/questions/41320747/ggplot2-reversing-the-standard-color-gradient-for-a-continuous-variable

```{r}
joined %>%
  ggplot(aes(line_comment_token, n, size = log(number_of_users), 
             color = log(number_of_users), label = title)) +
  scale_y_log10() +
  geom_text_repel(show.legend = FALSE) +
    scale_colour_gradient(high = "#08306b", low = "#6baed6") + 
   labs(title = "The Most Popular Language for Each Comment Token",
       subtitle = "Based on # Users and Rank",
       caption = "data from https://pldb.com/") +
  xlab("Token") +
  ylab("Number of languages using token") +
  theme_classic(base_size = 16) +
  theme(axis.text.x = element_text(face = "bold"))
```
