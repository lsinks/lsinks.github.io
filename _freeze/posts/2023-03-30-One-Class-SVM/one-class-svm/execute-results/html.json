{
  "hash": "6d34a3404610898f41783c6272943f6c",
  "result": {
    "markdown": "---\ntitle: \"One Class SVM\"\ndescription: \"One Class SVM for Imbalanced Classes\"\ntwitter-card:\n  image: \"thumbnail.png\"\nauthor:\n  - name: Louise E. Sinks\n    url: https://lsinks.github.io/\ndate: 03-30-2023\ncategories: [R, R-code, Code-Along, Machine Learning, caret, SVM, Classifiers] # self-defined categories\ncitation:\n  url: https://lsinks.github.io/posts/2023-03-30-One-Class-SVM\nimage: \"thumbnail.png\"\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\nI've recently been playing around with classification models, specifically on data sets with a skewed class distribution. In imbalanced classification problems, one class occurs infrequently. The minority class is often the class of interest (think fraudulent transaction, positive disease diagnosis, or intruder detection). Sometimes these applications are framed as a two-class classification problem, but other times they are called anomaly, outlier, or novelty detection.\n\nImbalanced classification problems are tricky for a couple of reasons. Models can achieve high accuracy by classifying everything as the dominant class. You can somewhat mitigate this problem by choosing models based on other metrics, such as sensitivity. You can also downsample the data to balance the classes (which throws out a lot of data) or upsample the infrequent class using a technique like SMOTE or ROSE to create synthetic data points.\n\nCollecting enough labeled data can also be expensive in highly imbalanced classes. Techniques like SMOTE won't help if you only have 2 of a class in the dataset; the model needs \"sufficient\" data to learn from.\n\nAnother way to handle a minority class is to use a one-class classifier. One-class classifiers are one of the most widely used methods in anomaly detection because it does not require extensive labeled data for training. This method can either be semi-supervised, where only the normal (major) class is used for training, or unsupervised, where the method can handle anomalies in the training class. The one-class SVM is a popular implementation of one-class classifiers.\n\nHere I'm going to use a [toy dataset from Datacamp](https://app.datacamp.com/learn/courses/introduction-to-anomaly-detection-in-r). They have told me that all datasets used in their courses can be used outside Datacamp.\n\nI'm using some specialty packages here, specifically e1071 and caret for the machine learning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(skimr) # for EDA\nlibrary(corrplot) # for cool correlation graph\nlibrary(gt) # for tables\nlibrary(e1071) # for svm\nlibrary(caret) # for data split\nthyroid <- read.csv(\"~/R Projects/SVM/thyroid.csv\", header = TRUE)\n```\n:::\n\n\n## Exploratory Data Analysis\n\nThe dataset explores thyroid disease as a function of thyroid hormone levels. I'm using a custom skim function to tailor the output. More info on that can be found [here](https://lsinks.github.io/posts/2023-03-24-tidytuesday-figure-polishing/).\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nmy_skim <- skim_with(numeric = sfl(p25 = NULL, p50 = NULL, p75 = NULL)) \nthyroid_skim <- my_skim(thyroid)\n\nthyroid_skim %>%\n  select(-skim_type)   %>% \n  gt() %>%\n  cols_label(n_missing = \"# Missing\", complete_rate = \"Completeness\", \n             numeric.mean = \"Mean\", numeric.sd = \"Standard Deviation\",\n             numeric.p0 = \"Min\", numeric.p100 = \"Max\",\n             numeric.hist = \"Histogram\") %>%\n  opt_stylize(style = 6, color = \"blue\", add_row_striping = TRUE) %>%\n  tab_header(title = \"Summary of Variables in Thyroid\") \n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"rzfmbicyxh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#rzfmbicyxh .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #5F5F5F;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#rzfmbicyxh .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#rzfmbicyxh .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#rzfmbicyxh .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#rzfmbicyxh .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#rzfmbicyxh .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n}\n\n#rzfmbicyxh .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #5F5F5F;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#rzfmbicyxh .gt_col_heading {\n  color: #FFFFFF;\n  background-color: #0076BA;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#rzfmbicyxh .gt_column_spanner_outer {\n  color: #FFFFFF;\n  background-color: #0076BA;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#rzfmbicyxh .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#rzfmbicyxh .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#rzfmbicyxh .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#rzfmbicyxh .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #5F5F5F;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#rzfmbicyxh .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #5F5F5F;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n  vertical-align: middle;\n}\n\n#rzfmbicyxh .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#rzfmbicyxh .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#rzfmbicyxh .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: none;\n  border-top-width: 1px;\n  border-top-color: #D5D5D5;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D5D5D5;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D5D5D5;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#rzfmbicyxh .gt_stub {\n  color: #333333;\n  background-color: #89D3FE;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D5D5D5;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rzfmbicyxh .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#rzfmbicyxh .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#rzfmbicyxh .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rzfmbicyxh .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #5F5F5F;\n}\n\n#rzfmbicyxh .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#rzfmbicyxh .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n}\n\n#rzfmbicyxh .gt_grand_summary_row {\n  color: #333333;\n  background-color: #D5D5D5;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rzfmbicyxh .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #5F5F5F;\n}\n\n#rzfmbicyxh .gt_striped {\n  background-color: #EDF7FC;\n}\n\n#rzfmbicyxh .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #5F5F5F;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #5F5F5F;\n}\n\n#rzfmbicyxh .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#rzfmbicyxh .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rzfmbicyxh .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#rzfmbicyxh .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rzfmbicyxh .gt_left {\n  text-align: left;\n}\n\n#rzfmbicyxh .gt_center {\n  text-align: center;\n}\n\n#rzfmbicyxh .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#rzfmbicyxh .gt_font_normal {\n  font-weight: normal;\n}\n\n#rzfmbicyxh .gt_font_bold {\n  font-weight: bold;\n}\n\n#rzfmbicyxh .gt_font_italic {\n  font-style: italic;\n}\n\n#rzfmbicyxh .gt_super {\n  font-size: 65%;\n}\n\n#rzfmbicyxh .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#rzfmbicyxh .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#rzfmbicyxh .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#rzfmbicyxh .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#rzfmbicyxh .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#rzfmbicyxh .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#rzfmbicyxh .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  <thead class=\"gt_header\">\n    <tr>\n      <td colspan=\"8\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Summary of Variables in Thyroid</td>\n    </tr>\n    \n  </thead>\n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"skim_variable\">skim_variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"# Missing\"># Missing</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Completeness\">Completeness</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Mean\">Mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Standard Deviation\">Standard Deviation</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Min\">Min</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Max\">Max</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Histogram\">Histogram</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left\">label</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right\">0.0220000</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right\">0.1467567</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right\">1.00000000</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left\">▇▁▁▁▁</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left gt_striped\">TSH</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right gt_striped\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right gt_striped\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right gt_striped\">-0.6881938</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right gt_striped\">0.4455654</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right gt_striped\">-4.532599</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right gt_striped\">-0.02173999</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left gt_striped\">▁▁▁▃▇</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left\">T3</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right\">-6.5046015</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right\">1.3994315</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right\">-9.268609</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right\">-1.43659510</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left\">▅▇▇▁▁</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left gt_striped\">TT4</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right gt_striped\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right gt_striped\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right gt_striped\">-1.7235631</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right gt_striped\">0.4421667</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right gt_striped\">-5.350910</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right gt_striped\">-0.37417607</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left gt_striped\">▁▁▁▇▁</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left\">T4U</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right\">-1.4666057</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right\">0.4495771</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right\">-6.164484</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right\">0.00000000</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left\">▁▁▁▇▂</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left gt_striped\">FTI</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right gt_striped\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right gt_striped\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right gt_striped\">-1.0093125</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right gt_striped\">0.2522809</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right gt_striped\">-3.569533</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right gt_striped\">-0.17950862</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left gt_striped\">▁▁▁▇▂</td></tr>\n    <tr><td headers=\"skim_variable\" class=\"gt_row gt_left\">TBG</td>\n<td headers=\"n_missing\" class=\"gt_row gt_right\">0</td>\n<td headers=\"complete_rate\" class=\"gt_row gt_right\">1</td>\n<td headers=\"numeric.mean\" class=\"gt_row gt_right\">-1.7932517</td>\n<td headers=\"numeric.sd\" class=\"gt_row gt_right\">0.4318577</td>\n<td headers=\"numeric.p0\" class=\"gt_row gt_right\">-6.636603</td>\n<td headers=\"numeric.p100\" class=\"gt_row gt_right\">0.00000000</td>\n<td headers=\"numeric.hist\" class=\"gt_row gt_left\">▁▁▁▇▁</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\nWe see that the dataset is complete with no missing values. All data types are numeric. About 2% of the patients are diagnosed with thyroid disease.\n\nI like to look at a correlation plot to get an overview of how the predictors relate to each other and the outcome. The correlation plot created by `corrplot()` has the title truncated in a lot of notebook/ markdown environments. The solution, which I found [here](https://stefaneng.github.io/corrplot-title-cut-off/), is to add a margin.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# examining correlation between variables categories\n# moving the outcome to the first column to start\n# will be sorted by decreasing correlation with outcome\nthyroid %>%\n    dplyr::select(label, everything()) %>%\n    cor %>%\n    \t{.[order(abs(.[, 1]), decreasing = TRUE), \n       order(abs(.[, 1]), decreasing = TRUE)]} %>% \n    corrplot( type = 'lower', tl.col = 'black', \n            addCoef.col = 'black', cl.ratio = 0.2, tl.srt = 45, \n            col = COL2('PuOr', 10), diag = FALSE , mar = c(0,0,2,0),\n            title = \" Correlations between Thyroid Disease and hormone levels\")\n```\n\n::: {.cell-output-display}\n![](one-class-svm_files/figure-html/corr-plot-1.png){width=672}\n:::\n:::\n\n\nMany of the features are strongly correlated with the outcome. So, we can expect to get reasonably decent results from our model.\n\n## Setting up for ML with caret\n\nI'm using the [e1071 package](https://cran.r-project.org/web/packages/e1071/index.html) for SVM, which is not supported by tidymodels, so I will use [caret](https://topepo.github.io/caret/index.html) as the wrapper for a lot of the machine modeling workflow. First, I'm going to make a train and test split. createDataPartition will stratify the sampling over the two classes if you pass it the vector of labels. Stratification is usually critical with an imbalanced dataset; you don't want a scenario where the train or test dataset has most of the minority class observations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Relabel the classes to TRUE if it is normal data and FALSE if it is\n# an anomaly.  (That is, it is false that the outlier data is normal).  \n# makes it easier to compare with the output of the SVM model.  \nthyroid <- thyroid %>%\n  mutate(label = ifelse(label == 0, TRUE, FALSE))\n\n# create data split for test and training\n# will be split among strata\nset.seed(2346)\ninTrain <- createDataPartition(thyroid$label, p = 0.6, list = FALSE) \n\n# formatting the data as required for svm()\ntrain_predictors <- thyroid[inTrain, 2:7]\ntrain_labels <- thyroid[inTrain, 1]\n\n# Creating the test set\ntest <- thyroid[-inTrain,]\n\n# formatting the data as required for svm()\ntest_predictors <- test[,2:7]\ntest_labels <- test[,1]\n\n#double checking that the test and train sets do contain ~2% disease\n# or rather 98% normal.\nmean(train_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9767055\n```\n:::\n\n```{.r .cell-code}\nmean(test_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9799499\n```\n:::\n:::\n\n\n## Two-class SVM\n\nFirst, I'm going to fit the data with a traditional 2 class classifier. I'm using SVM for the classification. The option `type ='C-classification'` performs normal classification. I'm not going to get into the details of SVM here, but for more information check out [this tutorial](https://www.r-bloggers.com/2017/04/machine-learning-using-support-vector-machines/). I'm also not going to tune any hyper-parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting SVM on training data \ntwo_class_svm_model <- svm(train_predictors, y = train_labels,\n               type = 'C-classification',\n               scale = TRUE,\n               kernel = \"radial\")\n\n# now predicting both classes on train and test data\ntwo_class_svm_predtrain <- predict(two_class_svm_model,train_predictors)\ntwo_class_svm_predtest <- predict(two_class_svm_model,test_predictors)\n\n\n# code below here will be provided\n# seeing how well the model did\ntwo_class_confTrain <- table(Predicted = two_class_svm_predtrain, Reference = train_labels)\ntwo_class_confTest <- table(Predicted = two_class_svm_predtest, Reference = test_labels)\n\n# printing out the results\nprint(\"These are the predictions on the training data:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"These are the predictions on the training data:\"\n```\n:::\n\n```{.r .cell-code}\nprint(two_class_confTrain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Reference\nPredicted FALSE TRUE\n    FALSE    12    0\n    TRUE      2  587\n```\n:::\n\n```{.r .cell-code}\nprint(\"These are the predictions on the test data:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"These are the predictions on the test data:\"\n```\n:::\n\n```{.r .cell-code}\nprint(two_class_confTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Reference\nPredicted FALSE TRUE\n    FALSE     6    0\n    TRUE      2  391\n```\n:::\n:::\n\n\nWe see that the two-class classifier does very well! In the test data set, it correctly predicts 397/ 399 data points. However, it misidentified a quarter of the disease patients as having normal thyroid. This is as I mentioned above- models can generally achieve good accuracy, but by over predicting the majority class. This result could potentially be unacceptable for a healthcare application.\n\n## One-class SVM\n\nNow, let's compare this to the one-class classifier. I will use the one-class classifier in supervised mode; that is, I will pass it labeled data, but only for the normal class. Then I will predict and calculate metrics based on both classes. There are a few different ways we can prepare this data. For ease of comparison with the regular classifier, I will use the same splits but filter out the anomalies from the training data. You might instead filter out all the outliers from the training set and add them to the test set, so you can get a better idea of how the model works for outlier detection. However, I want an apples-to-apples comparison, so I'm not doing that here. The regular and one class SVM will be predicting on the same test data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# subset the labeled data into the two classes\n# the normal class should be called \"train_normal\" and the anomaly\n# class should be called \"test_outlier\"\n\ntrain_normal_class <- subset(thyroid[inTrain, ], label == TRUE)\n\n\ntrain_normal_class_pred <- train_normal_class[,2:7]\ntrain_normal_class_label <- train_normal_class[,1]\n\n\n# fitting one class SVM on training data- no labels needed! \none_class_svm_model <- svm(train_normal_class_pred, y = NULL,\n               type = 'one-classification',\n               nu = 0.10,\n               scale = TRUE,\n               kernel = \"radial\")\n\n# now predicting both classes on train and test data\none_class_svm_predtrain <- predict(one_class_svm_model,train_normal_class_pred)\none_class_svm_predtest <- predict(one_class_svm_model,test_predictors)\n\n\n# code below here will be provided\n# seeing how well the model did\none_class_confTrain <- table(Predicted = one_class_svm_predtrain,\n                             Reference = train_normal_class_label)\none_class_confTest <- table(Predicted = one_class_svm_predtest,\n                            Reference = test_labels)\n\n# printing out the results\nprint(\"These are the predictions on the normal class training data only:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"These are the predictions on the normal class training data only:\"\n```\n:::\n\n```{.r .cell-code}\nprint(one_class_confTrain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Reference\nPredicted TRUE\n    FALSE   61\n    TRUE   526\n```\n:::\n\n```{.r .cell-code}\nprint(\"These are the predictions on the test data with both classes:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"These are the predictions on the test data with both classes:\"\n```\n:::\n\n```{.r .cell-code}\nprint(one_class_confTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Reference\nPredicted FALSE TRUE\n    FALSE     8   40\n    TRUE      0  351\n```\n:::\n:::\n\n\nThis model doesn't do quite as well, but it is pretty impressive given that it only learned on normal data. It correctly predicted 359/399 data points in the test set. It incorrectly classified 44 cases as abnormal when they were normal, but correctly found all 8 disease cases.\n\nSo now I've showed you how to use a one-class SVM to predict outliers. This is an incredible useful tool to keep in mind for classification tasks.\n",
    "supporting": [
      "one-class-svm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}