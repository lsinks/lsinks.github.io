{
  "hash": "ed9220b14b8e7a6921c757bd8f0fdbe8",
  "result": {
    "markdown": "---\ntitle: \"Self-Guided Learning through a Wordle Guess Generator: Part 2\"\ndescription: \"Current version of a Wordle Guess Generator\"\ntwitter-card:\n  image: \"thumbnail.png\"\nauthor:\n  - name: Louise E. Sinks\n    url: https://lsinks.github.io/\ndate: 04-01-2023\ncategories: [R, R-code] # self-defined categories\ncitation:\n  url: https://lsinks.github.io/posts/2023-04-01-self-guided-learning-wordle-guesser-part-2\nimage: \"thumbnail.png\"\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\nformat:\n  html:\n    toc: true\neditor: visual\n---\n\n\nThis is the current version of the word game guesser. I discussed how I used this project to hone my coding skills in the [companion blog post](https://lsinks.github.io/posts/2023-04-01-self-guided-learning-wordle-guesser-part-1/Wordle.htmll) to this one.\n\nI'm not going to walk through this in much detail, but I'm going to point out some of the major lessons I learned as I revised the code. Again, both the [initial version](https://github.com/lsinks/wordle) and [this version](https://github.com/lsinks/Word-Games) are on GitHub in all their messiness.\n\nI learned how to put functions in a separate file and call them from my many script. This can make long code much easier to read. Here, I've included the helper functions in-line and commented out the `source(\"code/helper-functions.R\")` in the main code. I've also set up switchable troubleshooting help with `verbose` and `debug_detail` parameters in my functions. Setting them to `TRUE` provide more info as the functions are executed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|label: helper-functions\nConstruct_Freq_Table <- function(word_list) {\n\n#scoring code uses the counting code from\n\n#https://www.r-bloggers.com/2018/12/rrrrs-in-r-letter-frequency-in-r-package-names/  \n# making the frequency table ----\n\nletters <- unlist(strsplit(word_list[,1], split = \"\"))\nchar_frequencies <- as.data.frame(table(letters))\n\n#normalized\ncommon <- max(char_frequencies[,2])\ny = (char_frequencies[,2]/common)\nchar_frequencies$normalized <- y\nreturn(char_frequencies)\n}\n\nScoring_Word <- function(word, freqs = char_frequencies,\n                         verbose = FALSE, debug_detail = FALSE){\n  letter_vec <-  unlist(strsplit(word, split = \"\"))\n    if (verbose == TRUE)\n    {message(\"I'm in Scoring_words message and scoring: \", word)}\n  \n  value <- 0\n  for (i in 1:length(letter_vec)) {\n    position <- letter_vec[i]== freqs$letters\n    value[i] <- freqs$normalized[position]\n    if (debug_detail == TRUE)\n    {\n      print(\"I am in the scoring loop calculating value: \")\n      print(i)\n      print(sum(value))\n      \n    }\n    \n    if (i == length(letter_vec)) {\n      \n      return(total <- sum(value))\n    }\n    \n  }\n  }\n  \n\nScoring_Word_Unique <- function(word, freqs = char_frequencies, \n                                verbose = FALSE, debug_detail = FALSE){\n  # This does only score on unique letters\n  letter_vec <-  unlist(strsplit(word, split = \"\"))\n  unique_letter_vec <- unique(letter_vec)\n  #unique_letter_vec <- letter_vec\n  if (verbose == TRUE)\n  {message(\"I'm in Scoring_words_Unique and scoring: \", word)}\n  \n  value <- 0\n  if (length(unique_letter_vec) == 0) {\n    return(value)\n  } else{\n    for (i in 1:length(unique_letter_vec)) {\n           position <- unique_letter_vec[i] == freqs$letters\n          value[i] <- freqs$normalized[position]\n      if (debug_detail == TRUE)\n      {\n        print(\"I am in the unique scoring loop calculating value: \")\n        print(i)\n        print(sum(value))\n      }\n      \n      if (i == length(unique_letter_vec)) {\n        \n        return(total <- sum(value))\n      }\n      \n    }\n  }\n}\n\nRemoving_Letters <- function(word, chosen_word, \n                              verbose = FALSE, debug_detail = FALSE) {\n  lvec <- gsub(paste0(\"[\", chosen_word, \"]\"), \"\", word)  \n  return(lvec)}\n```\n:::\n\n\nI finally did figure out how to make variables the types I wanted. I also replaced several loops with map functions from [purrr](https://purrr.tidyverse.org/). I also made a reshaped version of my dataframe using `pivot_longer` from [tidyr](https://tidyr.tidyverse.org/articles/pivot.html). Reshaping data is a really useful skill, but might be a bit confusing at first. So I certainly wanted to make sure I could do it correctly. The reshaped data is used to make a nice density plot later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading libraries and data ----\nlibrary(\"tidyverse\")\n\n\n#from https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\nword_list <- \n  read.table(\"C:/Users/drsin/OneDrive/Documents/R Projects/Word-Games/input/sgb-words.txt\") \n\n# Functions ----\n#source(\"code/helper-functions.R\")\n\n# calculate letter frequencies from word list\nchar_frequencies <- Construct_Freq_Table(word_list)\n\n# Initialize the word_scores dataframe ----\nnum_words <- nrow(word_list)\n#num_words <- 5\nword_scores <- data.frame(word_name = word_list[1:num_words,1],\n                    word_length = rep(0, times = num_words),\n                    word_guess1 = rep(0, times = num_words),\n                    word_guess2 = rep(0, times = num_words),\n                    word_guess3 = rep(0, times = num_words),\n                    word_guess4 = rep(0, times = num_words),\n                    score = rep(0, times = num_words), \n                    score_guess1 = rep(0, times = num_words),\n                    score_guess2 = rep(0, times = num_words),\n                    score_guess3 = rep(0, times = num_words),\n                    score_guess4 = rep(0, times = num_words)\n                                                )\n#fill in word lengths.  This is so code can be expended to longer words\nword_scores$word_length <-  str_length(word_scores$word_name)\n\n# Calculates the initial scores for all words -----\n\nword_scores <- word_scores %>% \n  mutate(score = map_dbl(word_name, Scoring_Word))\n\nword_scores <- word_scores %>%\n  mutate(score_guess1 = map_dbl(word_name, Scoring_Word_Unique))\n\n\n# Finding the best first word\ntop_words <- word_scores %>%\n arrange(desc(score_guess1))\nword_1 <- top_words$word_name[1]\n\n# Scoring for second guess\nword_scores <- word_scores %>%\n  mutate(word_guess2 = \n           map_chr(word_name, Removing_Letters, chosen_word = word_1))\nword_scores <- word_scores %>%\n  mutate(score_guess2 = map_dbl(word_guess2, Scoring_Word_Unique))\n\ntop_words <- word_scores %>%\n  arrange(desc(score_guess2))\n\nword_2 <- top_words$word_name[1]\n\n# Scoring for third guess\nword_scores <- word_scores %>% \n  mutate(word_guess3 =\n           map_chr(word_guess2, Removing_Letters, chosen_word = word_2))\nword_scores <- word_scores %>%\n  mutate(score_guess3 = map_dbl(word_guess3, Scoring_Word_Unique))\n\n\ntop_words <- word_scores %>%\n  arrange(desc(score_guess3))\nword_3 <- top_words$word_name[1]\n\n# Scoring for fourth guess\nword_scores <- word_scores %>%\n  mutate(word_guess4 = \n           map_chr(word_guess3, Removing_Letters, chosen_word = word_3))\nword_scores <- word_scores %>%\n  mutate(score_guess4 = map_dbl(word_guess4, Scoring_Word_Unique))\n\n\ntop_words <- word_scores %>%\n  arrange(desc(score_guess4))\n\nword_4 <- top_words$word_name[1]\n\n# subsetting this dataframe and reshaping it.\n# This is used to make a density plot later.\nword_scores2 <- word_scores %>%\n   select(word_name, score_guess1, score_guess2, score_guess3, score_guess4)\nword_scores_reshaped <- \n  pivot_longer(word_scores2, cols = 2:5, \n               names_to = \"score_type\", values_to = \"score\")\n```\n:::\n\n\nNice visualizations were definitely not part of the initial code. In the next chunk, I make some prettier visualizations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### This is now just visualizing what we've done. ------\n\n#plotting the frequency of the letters in our word_set\nggplot(char_frequencies, \n       aes(x = fct_rev(fct_reorder(letters,  normalized)), y = normalized )) +\n  geom_col() +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Frequencies of Letters\", caption = \"from 5 letter words\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  xlab(\"Letter\") +\n  ylab(\"Frequency\") +\n    scale_y_continuous(expand = c(0, 0))\n```\n\n::: {.cell-output-display}\n![](current_wordle_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## This looks at the distribution of scores as guessing occurs.  Initially, you have a\n\nword_scores_reshaped$score_type <- as.factor(word_scores_reshaped$score_type)\n\nggplot(word_scores_reshaped, aes(score, fill = score_type)) +\n  geom_density(alpha = 0.5) +\n  theme_classic() +\n  labs(title = \"Evolution of Word Scores as Guessing Progresses\",\n       caption = \"for 5 letter words\") +\n  xlab(\"Score\") +\n  ylab(\"Density\") +\n  labs(fill = \"\") +\n  theme(legend.position = c(0.7, 0.8)) +\n  scale_x_continuous( expand = c(0, 0)) +\n  scale_y_continuous( expand = c(0, 0)) \n```\n\n::: {.cell-output-display}\n![](current_wordle_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## Now we are visualizing what letters are picked in each guess\nguess <- rep(\"not guessed\", times = 26)\nchar_frequencies <- cbind(char_frequencies, guess)\n\n# this is done in reverse order because some letters are guessed in more than\n# one word and I'd like them marked at the earliest guess.\nletter_vec <-  unlist(strsplit(word_4, split = \"\"))\nprint(letter_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"w\" \"h\" \"a\" \"c\" \"k\"\n```\n:::\n\n```{.r .cell-code}\nfor (i in 1:length(letter_vec)) {\n  position <- letter_vec[i] == char_frequencies$letters\n  char_frequencies$guess[position] <- \"Guess 4\"\n}\n\nletter_vec <-  unlist(strsplit(word_3, split = \"\"))\nprint(letter_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"d\" \"u\" \"m\" \"p\" \"y\"\n```\n:::\n\n```{.r .cell-code}\nfor (i in 1:length(letter_vec)) {\n  position <- letter_vec[i] == char_frequencies$letters\n  char_frequencies$guess[position] <- \"Guess 3\"\n}\n\nletter_vec <-  unlist(strsplit(word_2, split = \"\"))\nprint(letter_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"u\" \"n\" \"t\" \"i\" \"l\"\n```\n:::\n\n```{.r .cell-code}\nfor (i in 1:length(letter_vec)) {\n  position <- letter_vec[i] == char_frequencies$letters\n  char_frequencies$guess[position] <- \"Guess 2\"\n}\n\n\nletter_vec <-  unlist(strsplit(word_1, split = \"\"))\nprint(letter_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"a\" \"r\" \"o\" \"s\" \"e\"\n```\n:::\n\n```{.r .cell-code}\nfor (i in 1:length(letter_vec)) {\n  position <- letter_vec[i] == char_frequencies$letters\n  char_frequencies$guess[position] <- \"Guess 1\"\n}\n\n\nggplot(char_frequencies, aes(\n  x = fct_rev(fct_reorder(letters,  normalized)),\n  y = normalized,\n  fill = guess)) +\n  geom_col() +\n  ggtitle(\"When Letters are Guessed\") +\n  ylab(\"Normalized Counts\") +\n  xlab(\"Letter\") +\n  theme_classic() +\n  theme(legend.position = c(0.6, 0.6)) +\n  scale_y_continuous(expand = c(0, 0))\n```\n\n::: {.cell-output-display}\n![](current_wordle_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n:::\n\n\nSo that's the current state of this project. This was a really useful project for me and it really strengthened by R and Tidyverse skills.\n",
    "supporting": [
      "current_wordle_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}